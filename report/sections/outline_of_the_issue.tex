% Give a brief overview of what the project is and what the intended outcomes are.
% Emphasise the potential benefits of the project with quantifiable information.
% We should frame this as a problem to be solved

\section{Outline of the issue or opportunity and the business problem to be solved}

The BBC produces and stores a vast amount of metadata for its content, and this metadata is surfaced by countless services and APIs.
One of the priority for the BBC is to increae the adoption across the business of "Passport" \cite{BbcPassportMetadata}, an internal service that generates,
stores, manages and provides access to a richer dataset of metadata annotations for multi modal content (audio, video and text).
The usage in production is very low, and its adoption would make the access to metadata consistent BBC-wide,
removing duplications and reducing effort and costs.

The similarity score of the current C2C recommender is directly proportional to the number of values in common between any pairs of items
on a per-feature basis. But the commonality is calculated with an exact string equality, hence it ignores any relationship between different
categorical values expressing a similar concept (e.g. "comedy", "stand-up comedy").

The number and types of tags are not enough to sufficiently
describe the content.

The data distribution is severely skewed towards the most popular category and no pre-processing
is applied.

Lastly, each similarity score is multiplied by a hardcoded weight that modulates the importance of a feature, but it doesn't solve
the polarising effect of a skewed distribution. Unfortunately, because they are hyperparameters and not learned weights, the model can't improve
its performances by minimising them against a cost function.
\\ \\
To address these issues, the aim of this project was:

\begin{itemize}
  \item \textbf{To improve the quality of the C2C similarity recommendations}. The hypothesis was that by using in input a richer set of metadata that
  better describes the content, and by reducing the high-dimensional data to a lower-dimensional latent manifold,
  the model is able to generate embeddings that can improve the performances of the model by mapping the
  item similarity problem to a geometric distance calculation between vectors in a multi-dimensional Euclidean space.
  \item \textbf{To reduce the costs to generate C2C similarity recommendations}. I sourced the input
  data from Passport, to build a BBC-wide general solution that could be used by any product and applied to any type of content,
  because they all share the same set of annotations.
  \item \textbf{To build a foundational item-embeddings generator}. Content-based recommenders
  use item metadata. This project provided an immediate solution for C2C unpersonalised recommendations that solely relies on them and
  it also provided a foundational approach for personalised recommender that combine content metadata with other information like user interactions
  and contextual data.
\end{itemize}
