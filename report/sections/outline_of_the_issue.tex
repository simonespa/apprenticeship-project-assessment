% Give a brief overview of what the project is and what the intended outcomes are.
% Emphasise the potential benefits of the project with quantifiable information.
% We should frame this as a problem to be solved

\section{Outline of the issue or opportunity and the business problem to be solved}

The BBC produces and stores a vast amount of metadata for its content, and it is surfaced by countless services and APIs.
One of the priority for the BBC is to increae the adoption across the business of "Passport", an internal service that generates,
stores and provides access to a richer dataset of metadata annotations for multi modal content (audio, video and text).
The usage in production is very low if not existent, and its adoption would make the access to metadata consistent,
removing duplications and reducing effort and costs.

Furthermore, the similarity score of the current C2C recommender is directly proportional to the number of values in common between any pairs of items
on a per-feature basis. But the commonality is calculated with an exact string equality, hence it ignores any relationship between different
strings expressing a similar concept (e.g. "comedy", "stand-up comedy"). The number and types of tags are not enough to sufficiently
describe the content. The data distribution of each feature
is severely skewed towards the most popular category and no pre-processing is applied. Lastly, each feature similarity score
is multiplied by a weight to manually set the importance, but unfortunately, it doesn't solve the polarising effect of a
skewed distribution and because they are hyperparameters and not learned weights, the model can't improve
its performances by minimising them against a cost function.

To address these issues, the aim of this project is:

\begin{itemize}
  \item \textbf{To improve the quality of the recommendations}. My hypothesis was that by using in input a richer set of metadata that
  better describes the content, and by reducing the high-dimensional data to a lower-dimensional latent manifold,
  the model is able to generate embeddings that can improve the performances of the model by mapping the
  item similarity problem to a geometric distance calculation between vectors in a multi-dimensional Euclidean space.
  \item \textbf{To reduce the costs to generate C2C similarity recommendations}. I sourced the
  data from Passport, to build a BBC-wide general solution that can be used by any product and can be applied to any content recommendation,
  because they all share the same set of annotations.
\end{itemize}
